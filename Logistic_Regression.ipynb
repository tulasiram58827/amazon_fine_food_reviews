{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tulasi ram\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing sqlite3\n",
    "import sqlite3\n",
    "#creating connection with the DataBase file.\n",
    "#Here in final.sqlite  already preprocessed data is added in one column named Cleaned Text\n",
    "con=sqlite3.connect('C:\\\\Users\\\\tulasi ram\\\\Desktop\\\\amazon_food_reviews\\\\final.sqlite')\n",
    "final_data=pd.read_sql_query(\"\"\"SELECT * FROM Reviews \"\"\", con)\n",
    "#it is always required to close the connection\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'Id', 'ProductId', 'UserId', 'ProfileName',\n",
      "       'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time',\n",
      "       'Summary', 'Text', 'CleanedText', 'WordCount'],\n",
      "      dtype='object')\n",
      "(364171, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "positive    307061\n",
       "negative     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(final_data.columns)\n",
    "print(final_data.shape)\n",
    "final_data['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57110, 13)\n",
      "(307061, 13)\n",
      "Negative reviews shape (5000, 13)\n",
      "Positive reviews shape (5000, 13)\n",
      "Sampled data shape (10000, 13)\n"
     ]
    }
   ],
   "source": [
    "#Selecting the sample of the dataframe for the operations\n",
    "\n",
    "\n",
    "Negative = final_data.loc[final_data['Score'] == 'negative']\n",
    "Positive = final_data.loc[final_data['Score'] == 'positive']\n",
    "\n",
    "print(Negative.shape)\n",
    "print(Positive.shape)\n",
    "\n",
    "#As the data looks to be imbalanced we are sampling the data and making it balanced\n",
    "np.random.seed(100)\n",
    "indices=np.random.randint(0, 57110, size=5000)\n",
    "Negative = Negative.iloc[indices]\n",
    "print('Negative reviews shape', Negative.shape)\n",
    "indices=np.random.randint(0, 307061, size=5000)\n",
    "Positive = Positive.iloc[indices]\n",
    "print('Positive reviews shape', Positive.shape)\n",
    "sampled_data=pd.concat([Negative,Positive],ignore_index=False)\n",
    "print('Sampled data shape', sampled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>WordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>346041</td>\n",
       "      <td>374343</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A1B2IZU1JLZA6</td>\n",
       "      <td>Wes</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>negative</td>\n",
       "      <td>948240000</td>\n",
       "      <td>WARNING: CLAMSHELL EDITION IS EDITED TV VERSION</td>\n",
       "      <td>I, myself always enjoyed this movie, it's very...</td>\n",
       "      <td>b'alway enjoy movi funni entertain didnt hesit...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>346077</td>\n",
       "      <td>374382</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A3C3BAQDZWH5YE</td>\n",
       "      <td>Kushana no shinryaku (Kushana's invasion)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1014681600</td>\n",
       "      <td>...</td>\n",
       "      <td>It was on the other night, and, having been a ...</td>\n",
       "      <td>b'night big fan cartoon shown decid watch also...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>346040</td>\n",
       "      <td>374342</td>\n",
       "      <td>B00004CI84</td>\n",
       "      <td>A10L8O1ZMUIMR2</td>\n",
       "      <td>G. Kleinschmidt</td>\n",
       "      <td>61</td>\n",
       "      <td>79</td>\n",
       "      <td>negative</td>\n",
       "      <td>1040947200</td>\n",
       "      <td>Great movie turned bad</td>\n",
       "      <td>Just to let you know, this movie is one of my ...</td>\n",
       "      <td>b'let know movi one person favorit ghost movi ...</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>38888</td>\n",
       "      <td>42226</td>\n",
       "      <td>B0000A0BS8</td>\n",
       "      <td>A23GFTVIETX7DS</td>\n",
       "      <td>Debbie Lee Wesselmann</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>1067904000</td>\n",
       "      <td>Five stars if you like Starbucks</td>\n",
       "      <td>This blend is one of Starbucks' gentler blends...</td>\n",
       "      <td>b'blend one starbuck gentler blend like tast s...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>224637</td>\n",
       "      <td>243579</td>\n",
       "      <td>B0000DIYKD</td>\n",
       "      <td>AYHW6HJSUCSAE</td>\n",
       "      <td>\"insolent_shoeshine_grrl\"</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>positive</td>\n",
       "      <td>1072656000</td>\n",
       "      <td>Fantastic Real Licorice From The Land Down Under</td>\n",
       "      <td>I recently purchased a bag of Kookaburra Black...</td>\n",
       "      <td>b'recent purchas bag kookaburra black licoric ...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index      Id   ProductId          UserId  \\\n",
       "308   346041  374343  B00004CI84   A1B2IZU1JLZA6   \n",
       "362   346077  374382  B00004CI84  A3C3BAQDZWH5YE   \n",
       "365   346040  374342  B00004CI84  A10L8O1ZMUIMR2   \n",
       "2293   38888   42226  B0000A0BS8  A23GFTVIETX7DS   \n",
       "4682  224637  243579  B0000DIYKD   AYHW6HJSUCSAE   \n",
       "\n",
       "                                    ProfileName  HelpfulnessNumerator  \\\n",
       "308                                         Wes                    19   \n",
       "362   Kushana no shinryaku (Kushana's invasion)                     0   \n",
       "365                             G. Kleinschmidt                    61   \n",
       "2293                      Debbie Lee Wesselmann                     5   \n",
       "4682                  \"insolent_shoeshine_grrl\"                    11   \n",
       "\n",
       "      HelpfulnessDenominator     Score        Time  \\\n",
       "308                       23  negative   948240000   \n",
       "362                        1  positive  1014681600   \n",
       "365                       79  negative  1040947200   \n",
       "2293                       5  positive  1067904000   \n",
       "4682                      13  positive  1072656000   \n",
       "\n",
       "                                               Summary  \\\n",
       "308    WARNING: CLAMSHELL EDITION IS EDITED TV VERSION   \n",
       "362                                                ...   \n",
       "365                             Great movie turned bad   \n",
       "2293                  Five stars if you like Starbucks   \n",
       "4682  Fantastic Real Licorice From The Land Down Under   \n",
       "\n",
       "                                                   Text  \\\n",
       "308   I, myself always enjoyed this movie, it's very...   \n",
       "362   It was on the other night, and, having been a ...   \n",
       "365   Just to let you know, this movie is one of my ...   \n",
       "2293  This blend is one of Starbucks' gentler blends...   \n",
       "4682  I recently purchased a bag of Kookaburra Black...   \n",
       "\n",
       "                                            CleanedText  WordCount  \n",
       "308   b'alway enjoy movi funni entertain didnt hesit...         32  \n",
       "362   b'night big fan cartoon shown decid watch also...         38  \n",
       "365   b'let know movi one person favorit ghost movi ...        114  \n",
       "2293  b'blend one starbuck gentler blend like tast s...         59  \n",
       "4682  b'recent purchas bag kookaburra black licoric ...         95  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data=sampled_data.sort_values(by=['Time'])\n",
    "\n",
    "sorted_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis using bag of words vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 13237)\n"
     ]
    }
   ],
   "source": [
    "#Bow\n",
    "bow_vectors=CountVectorizer(binary = True).fit_transform(sorted_data['CleanedText'].values)\n",
    "print(bow_vectors.shape)\n",
    "np.save('bow_vectors1',bow_vectors.toarray())\n",
    "final_bow=bow_vectors.toarray()\n",
    "labels=sorted_data['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tulasi ram\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 13237)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardized_data=StandardScaler().fit_transform(final_bow)\n",
    "print(standardized_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "#Splitting the data into train and test \n",
    "X_1, X_test, Y_1, Y_test=cross_validation.train_test_split(standardized_data , labels, test_size=0.35 ,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "The accuracy of the model is %f%%  84.17142857142858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Using GridSearchCV\n",
    "#As it is balanced data taking scoring parameter as accuracy is also good\n",
    "tuned_parameters = [{'C': [10**-4,10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3 ,10**4]}]\n",
    "grid_search = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', cv=10)\n",
    "grid_search.fit(X_1,Y_1)\n",
    "\n",
    "print(grid_search.best_estimator_)\n",
    "print(\"The accuracy of the model is %f%% \",grid_search.score(X_test, Y_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.10535917233957426, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "The accuracy of the model is %f%%  81.77142857142857\n"
     ]
    }
   ],
   "source": [
    "#Using RandomSearch\n",
    "\n",
    "parameters = {'C' : list(filter(lambda x: x>0, norm.rvs(size=50)))}\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), parameters, scoring = 'accuracy', cv=5)\n",
    "random_search.fit(X_1,Y_1)\n",
    "\n",
    "print(random_search.best_estimator_)\n",
    "print(\"\\nThe accuracy of the model is %f%% \",random_search.score(X_test, Y_test)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accuracy using randomized search is almost same as accuracy of grid search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00285247 -0.00629317  0.00174559 -0.0029502   0.00985739  0.00119812\n",
      "   0.00526796  0.00753386  0.00222016]]\n",
      "13237\n",
      "\n",
      "The accuracy of the LR classifier is %f%% 84.17142857142858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = LogisticRegression(C=0.001, penalty='l2');\n",
    "clf.fit(X_1, Y_1);\n",
    "w = clf.coef_\n",
    "\n",
    "print(w[:,0:9])\n",
    "print(np.count_nonzero(w))\n",
    "# predict the response\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc = accuracy_score(Y_test, pred) * 100\n",
    "print('\\nThe accuracy of the LR classifier is %f%%' , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The non zero values in the weight vector with C value 1 is 2832\n",
      "The accuracy of the LR classifier with C value 1  is %f%% 82.17142857142858\n",
      "\n",
      "The non zero values in the weight vector with C value 0.1 is 2402\n",
      "The accuracy of the LR classifier with C value 0.1  is %f%% 83.2\n",
      "\n",
      "The non zero values in the weight vector with C value 0.01 is 196\n",
      "The accuracy of the LR classifier with C value 0.01  is %f%% 81.05714285714286\n",
      "\n",
      "The non zero values in the weight vector with C value 0.001 is 0\n",
      "The accuracy of the LR classifier with C value 0.001  is %f%% 49.94285714285714\n",
      "\n",
      "The non zero values in the weight vector with C value 0.0001 is 0\n",
      "The accuracy of the LR classifier with C value 0.0001  is %f%% 49.94285714285714\n"
     ]
    }
   ],
   "source": [
    "List=[1,0.1,0.01,0.001,0.0001]\n",
    "for i in List:\n",
    "    clf = LogisticRegression(C=i, penalty='l1');\n",
    "    clf.fit(X_1, Y_1);\n",
    "    w = clf.coef_\n",
    "    \n",
    "    print('\\nThe non zero values in the weight vector with C value', i ,'is',np.count_nonzero(w))\n",
    "    # predict the response\n",
    "    pred = clf.predict(X_test)\n",
    "    # evaluate accuracy\n",
    "    acc = accuracy_score(Y_test, pred) * 100\n",
    "    print('The accuracy of the LR classifier with C value',i ,' is %f%%' , acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "It is clear that decreasing the values of C i.e, increaing the values of lambda sparsity of the weight vector is increasing and when C=0.001 the weight vector becomes completely 0.\n",
    "\n",
    "It is also understood that while increasing the values of lambda accuracy is decreasing and error is increasing finally performance of the model is decreasing\n",
    "\n",
    "Here when C values are less than 0.001 the accuracy is even less than 50 percent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Analysis using tfidf vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 13237)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,1))\n",
    "final_tf_idf = tf_idf_vect.fit_transform(sorted_data['CleanedText'].values)\n",
    "print(final_tf_idf.shape)\n",
    "final_tf_idf_vectors=final_tf_idf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 13237)\n"
     ]
    }
   ],
   "source": [
    "#Standardizing the data .\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardized_data=StandardScaler().fit_transform(final_tf_idf_vectors)\n",
    "print(standardized_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting the data into train and test \n",
    "X_1, X_test, Y_1, Y_test=cross_validation.train_test_split(standardized_data , labels, test_size=0.35 ,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "The accuracy of the model is %f%%  83.71428571428572\n"
     ]
    }
   ],
   "source": [
    "#Using GridSearchCV\n",
    "#As it is balanced data taking scoring parameter as accuracy is also good\n",
    "tuned_parameters = [{'C': [10**-4,10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3 ,10**4]}]\n",
    "grid_search = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', cv=10)\n",
    "grid_search.fit(X_1,Y_1)\n",
    "\n",
    "print(grid_search.best_estimator_)\n",
    "print(\"The accuracy of the model is %f%% \",grid_search.score(X_test, Y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.3280456967491141, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "The accuracy of the model is %f%%  80.11428571428571\n"
     ]
    }
   ],
   "source": [
    "#Using RandomSearch\n",
    "\n",
    "parameters = {'C' : list(filter(lambda x: x>0, norm.rvs(size=50)))}\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), parameters, scoring = 'accuracy', cv=5)\n",
    "random_search.fit(X_1,Y_1)\n",
    "\n",
    "print(random_search.best_estimator_)\n",
    "print(\"\\nThe accuracy of the model is %f%% \",random_search.score(X_test, Y_test)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here also the accuracy using randomized search is almost same as accuracy of grid search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00260612 -0.00299843  0.00160532 -0.00103442  0.00300244  0.00104636\n",
      "   0.00257714  0.00319687  0.00102679]]\n",
      "13237\n",
      "\n",
      "The accuracy of the LR classifier is %f%% 83.71428571428572\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = LogisticRegression(C=0.0001, penalty='l2');\n",
    "clf.fit(X_1, Y_1);\n",
    "w = clf.coef_\n",
    "\n",
    "print(w[:,0:9])\n",
    "print(np.count_nonzero(w))\n",
    "# predict the response\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc = accuracy_score(Y_test, pred) * 100\n",
    "print('\\nThe accuracy of the LR classifier is %f%%' , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The non zero values in the weight vector with C value 1 is 3427\n",
      "The accuracy of the LR classifier with C value 1  is %f%% 82.31428571428572\n",
      "\n",
      "The non zero values in the weight vector with C value 0.1 is 2915\n",
      "The accuracy of the LR classifier with C value 0.1  is %f%% 83.54285714285714\n",
      "\n",
      "The non zero values in the weight vector with C value 0.01 is 186\n",
      "The accuracy of the LR classifier with C value 0.01  is %f%% 80.91428571428571\n",
      "\n",
      "The non zero values in the weight vector with C value 0.001 is 0\n",
      "The accuracy of the LR classifier with C value 0.001  is %f%% 49.94285714285714\n",
      "\n",
      "The non zero values in the weight vector with C value 0.0001 is 0\n",
      "The accuracy of the LR classifier with C value 0.0001  is %f%% 49.94285714285714\n"
     ]
    }
   ],
   "source": [
    "List=[1,0.1,0.01,0.001,0.0001]\n",
    "for i in List:\n",
    "    clf = LogisticRegression(C=i, penalty='l1');\n",
    "    clf.fit(X_1, Y_1);\n",
    "    w = clf.coef_\n",
    "    \n",
    "    print('\\nThe non zero values in the weight vector with C value', i ,'is',np.count_nonzero(w))\n",
    "    # predict the response\n",
    "    pred = clf.predict(X_test)\n",
    "    # evaluate accuracy\n",
    "    acc = accuracy_score(Y_test, pred) * 100\n",
    "    print('The accuracy of the LR classifier with C value',i ,' is %f%%' , acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "It is clear that decreasing the values of C i.e, increaing the values of lambda sparsity of the weight vector is increasing and when C=0.001 the weight vector becomes completely 0.\n",
    "\n",
    "It is also understood that while increasing the values of lambda accuracy is decreasing and error is increasing finally performance of the model is decreasing\n",
    "\n",
    "Here when C values are less than 0.001 the accuracy is even less than 50 percent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis using avg W2V vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train our own Word2Vec model using our own text corpus\n",
    "# cleaning the word of any html-tags\n",
    "#cleaning the word of any punctuation or special characters\n",
    "import gensim\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in sorted_data['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Word2Vec\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model.save('word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AvgW2V Model\n",
    "sent_vectors = []; \n",
    "for sent in list_of_sent: \n",
    "    sent_vec = np.zeros(50) \n",
    "    cnt_words =0; \n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50)\n"
     ]
    }
   ],
   "source": [
    "#Standardizing the data .\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardized_data=StandardScaler().fit_transform(sent_vectors)\n",
    "print(standardized_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Splitting the data into train and test \n",
    "X_1, X_test, Y_1, Y_test=cross_validation.train_test_split(standardized_data , labels, test_size=0.35 ,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "The accuracy of the model is %f%%  77.45714285714286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Using GridSearchCV\n",
    "#As it is balanced data taking scoring parameter as accuracy is also good\n",
    "tuned_parameters = [{'C': [10**-4,10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3 ,10**4]}]\n",
    "grid_search = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', cv=10)\n",
    "grid_search.fit(X_1,Y_1)\n",
    "\n",
    "print(grid_search.best_estimator_)\n",
    "print(\"The accuracy of the model is %f%% \",grid_search.score(X_test, Y_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.46819318791272424, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "The accuracy of the model is %f%%  77.57142857142857\n"
     ]
    }
   ],
   "source": [
    "#Using RandomSearch\n",
    "\n",
    "parameters = {'C' : list(filter(lambda x: x>0, norm.rvs(size=50)))}\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), parameters, scoring = 'accuracy', cv=5)\n",
    "random_search.fit(X_1,Y_1)\n",
    "\n",
    "print(random_search.best_estimator_)\n",
    "print(\"\\nThe accuracy of the model is %f%% \",random_search.score(X_test, Y_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00822811 -0.33204779  0.30584753 -0.58985789 -0.22889732 -0.00666807\n",
      "   0.47102095 -0.27127216 -0.49164818]]\n",
      "50\n",
      "\n",
      "The accuracy of the LR classifier is %f%% 77.60000000000001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = LogisticRegression(C=0.46, penalty='l2');\n",
    "clf.fit(X_1, Y_1);\n",
    "w = clf.coef_\n",
    "\n",
    "print(w[:,0:9])\n",
    "print(np.count_nonzero(w))\n",
    "# predict the response\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate accuracy\n",
    "acc = accuracy_score(Y_test, pred) * 100\n",
    "print('\\nThe accuracy of the LR classifier is %f%%' , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The non zero values in the weight vector with C value 1 is 47\n",
      "The accuracy of the LR classifier with C value 1  is %f%% 77.42857142857143\n",
      "\n",
      "The non zero values in the weight vector with C value 0.1 is 40\n",
      "The accuracy of the LR classifier with C value 0.1  is %f%% 76.97142857142858\n",
      "\n",
      "The non zero values in the weight vector with C value 0.01 is 23\n",
      "The accuracy of the LR classifier with C value 0.01  is %f%% 73.94285714285715\n",
      "\n",
      "The non zero values in the weight vector with C value 0.001 is 0\n",
      "The accuracy of the LR classifier with C value 0.001  is %f%% 49.94285714285714\n",
      "\n",
      "The non zero values in the weight vector with C value 0.0001 is 0\n",
      "The accuracy of the LR classifier with C value 0.0001  is %f%% 49.94285714285714\n"
     ]
    }
   ],
   "source": [
    "List=[1,0.1,0.01,0.001,0.0001]\n",
    "for i in List:\n",
    "    clf = LogisticRegression(C=i, penalty='l1');\n",
    "    clf.fit(X_1, Y_1);\n",
    "    w = clf.coef_\n",
    "    \n",
    "    print('\\nThe non zero values in the weight vector with C value', i ,'is',np.count_nonzero(w))\n",
    "    # predict the response\n",
    "    pred = clf.predict(X_test)\n",
    "    # evaluate accuracy\n",
    "    acc = accuracy_score(Y_test, pred) * 100\n",
    "    print('The accuracy of the LR classifier with C value',i ,' is %f%%' , acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Google W2V**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Google News Word2Vectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AvgW2V Model\n",
    "sent_vectors_googlew2v = []; \n",
    "for sent in list_of_sent: \n",
    "    sent_vec = np.zeros(300) \n",
    "    cnt_words =0; \n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec = model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors_googlew2v.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 300)\n"
     ]
    }
   ],
   "source": [
    "#Standardizing the data .\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardized_data=StandardScaler().fit_transform(sent_vectors_googlew2v)\n",
    "print(standardized_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Splitting the data into train and test \n",
    "X_1, X_test, Y_1, Y_test=cross_validation.train_test_split(standardized_data , labels, test_size=0.35 ,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "The accuracy of the model is %f%%  83.57142857142857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Using GridSearchCV\n",
    "#As it is balanced data taking scoring parameter as accuracy is also good\n",
    "tuned_parameters = [{'C': [10**-4,10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2, 10**3 ,10**4]}]\n",
    "grid_search = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', cv=10)\n",
    "grid_search.fit(X_1,Y_1)\n",
    "\n",
    "print(grid_search.best_estimator_)\n",
    "print(\"The accuracy of the model is %f%% \",grid_search.score(X_test, Y_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.10750374094965869, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "The accuracy of the model is %f%%  83.0\n"
     ]
    }
   ],
   "source": [
    "#Using RandomSearch\n",
    "\n",
    "parameters = {'C' : list(filter(lambda x: x>0, norm.rvs(size=50)))}\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), parameters, scoring = 'accuracy', cv=5)\n",
    "random_search.fit(X_1,Y_1)\n",
    "\n",
    "print(random_search.best_estimator_)\n",
    "print(\"\\nThe accuracy of the model is %f%% \",random_search.score(X_test, Y_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The non zero values in the weight vector with C value 1 is 295\n",
      "The accuracy of the LR classifier with C value 1  is %f%% 82.94285714285714\n",
      "\n",
      "The non zero values in the weight vector with C value 0.1 is 231\n",
      "The accuracy of the LR classifier with C value 0.1  is %f%% 83.28571428571429\n",
      "\n",
      "The non zero values in the weight vector with C value 0.01 is 79\n",
      "The accuracy of the LR classifier with C value 0.01  is %f%% 80.82857142857142\n",
      "\n",
      "The non zero values in the weight vector with C value 0.001 is 0\n",
      "The accuracy of the LR classifier with C value 0.001  is %f%% 49.94285714285714\n",
      "\n",
      "The non zero values in the weight vector with C value 0.0001 is 0\n",
      "The accuracy of the LR classifier with C value 0.0001  is %f%% 49.94285714285714\n"
     ]
    }
   ],
   "source": [
    "List=[1,0.1,0.01,0.001,0.0001]\n",
    "for i in List:\n",
    "    clf = LogisticRegression(C=i, penalty='l1');\n",
    "    clf.fit(X_1, Y_1);\n",
    "    w = clf.coef_\n",
    "    \n",
    "    print('\\nThe non zero values in the weight vector with C value', i ,'is',np.count_nonzero(w))\n",
    "    # predict the response\n",
    "    pred = clf.predict(X_test)\n",
    "    # evaluate accuracy\n",
    "    acc = accuracy_score(Y_test, pred) * 100\n",
    "    print('The accuracy of the LR classifier with C value',i ,' is %f%%' , acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINAL CONCLUSION**\n",
    "\n",
    "Of all these types of vectors BOW vectors is giving slightly more accuracy than other vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
